package com.nervesparks.iris.viewmodel

import timber.log.Timber
import android.app.ActivityManager
import android.content.Context
import androidx.compose.runtime.getValue
import androidx.compose.runtime.mutableIntStateOf
import androidx.compose.runtime.mutableLongStateOf
import androidx.compose.runtime.mutableStateOf
import androidx.compose.runtime.setValue
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.nervesparks.iris.data.exceptions.ErrorHandler
import dagger.hilt.android.lifecycle.HiltViewModel
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.delay
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import javax.inject.Inject
import kotlin.system.measureTimeMillis

/**
 * PHASE 1.1.2: GenerationViewModel - Extracted from MainViewModel
 * Handles text generation, performance tracking, and generation state management
 */
@HiltViewModel
class GenerationViewModel @Inject constructor(
    private val context: Context,
    private val errorHandler: ErrorHandler
) : ViewModel() {

    init {
        // Start background memory monitoring
        startMemoryMonitoring()
    }

    // Generation state
    var isGenerating by mutableStateOf(false)
        private set

    // Code analysis mode
    var isCodeMode by mutableStateOf(false)
        private set

    var generationStartTime by mutableLongStateOf(0L)
        private set

    var tokensGenerated by mutableIntStateOf(0)
        private set

    var totalGenerationTime by mutableLongStateOf(0L)
        private set

    // Performance metrics
    var tps by mutableStateOf(0.0) // Tokens per second
        private set

    var ttft by mutableLongStateOf(0L) // Time to first token (milliseconds)
        private set

    var latency by mutableLongStateOf(0L) // Average latency per token (milliseconds)
        private set

    var memoryUsage by mutableLongStateOf(0L) // Memory usage in MB
        private set

    var contextLimit by mutableIntStateOf(0) // Current context length
        private set

    var maxContextLimit by mutableIntStateOf(0) // Maximum context limit
        private set

    var offloadedLayers by mutableIntStateOf(-1)
        private set

    var totalLayers by mutableIntStateOf(-1)
        private set

    // Memory monitoring
    private val _memoryPressureWarning = mutableStateOf(false)
    val memoryPressureWarning: Boolean by _memoryPressureWarning

    /**
     * Toggle code analysis mode
     */
    fun toggleCodeMode() {
        isCodeMode = !isCodeMode
        Timber.d("Code mode toggled to: $isCodeMode")
    }

    /**
     * Start generation tracking
     */
    fun startGeneration() {
        generationStartTime = System.currentTimeMillis()
        isGenerating = true
        ttft = 0L
        tokensGenerated = 0
        Timber.d("Generation started at $generationStartTime")
    }

    /**
     * End generation tracking and calculate final metrics
     */
    fun endGeneration() {
        if (generationStartTime > 0) {
            val endTime = System.currentTimeMillis()
            val duration = endTime - generationStartTime
            totalGenerationTime = duration

            if (tokensGenerated > 0) {
                tps = tokensGenerated.toDouble() / (duration / 1000.0)
                latency = duration / tokensGenerated
            }

            Timber.d("Generation ended. Duration: ${duration}ms, Tokens: $tokensGenerated, TPS: $tps")
        }

        isGenerating = false
    }

    /**
     * Update token count during generation
     */
    fun updateTokenCount(count: Int) {
        val previousCount = tokensGenerated
        tokensGenerated = count

        // Calculate TTFT on first token
        if (previousCount == 0 && count > 0 && generationStartTime > 0) {
            ttft = System.currentTimeMillis() - generationStartTime
            Timber.d("Time to first token: ${ttft}ms")
        }
    }

    /**
     * Update memory usage
     */
    fun updateMemoryUsage(usageMB: Long) {
        memoryUsage = usageMB
    }

    /**
     * Get current memory usage
     */
    fun getCurrentMemoryUsage(): Long {
        return try {
            val activityManager = context.getSystemService(Context.ACTIVITY_SERVICE) as ActivityManager
            val memoryInfo = ActivityManager.MemoryInfo()
            activityManager.getMemoryInfo(memoryInfo)

            // Calculate used memory (total - available)
            val totalMemory = memoryInfo.totalMem
            val availableMemory = memoryInfo.availMem
            val usedMemory = totalMemory - availableMemory

            // Convert to MB
            val newMemoryUsage = (usedMemory / (1024 * 1024)).toLong()

            // Update cached value
            memoryUsage = newMemoryUsage
            newMemoryUsage
        } catch (e: Exception) {
            Timber.e(e, "Failed to get memory usage")
            errorHandler.reportError(e, "Memory measurement failed")
            memoryUsage // Return last known value
        }
    }

    /**
     * Start background memory monitoring to avoid blocking UI thread
     */
    fun startMemoryMonitoring() {
        viewModelScope.launch(Dispatchers.IO) {
            while (true) {
                try {
                    getCurrentMemoryUsage() // Updates cached memoryUsage
                    // Check for memory pressure
                    val activityManager = context.getSystemService(Context.ACTIVITY_SERVICE) as ActivityManager
                    val memoryInfo = ActivityManager.MemoryInfo()
                    activityManager.getMemoryInfo(memoryInfo)

                    if (memoryInfo.lowMemory) {
                        Timber.w("Low memory warning - used: ${memoryUsage}MB")
                        // Trigger memory optimization if needed
                        _memoryPressureWarning.value = true
                    } else {
                        _memoryPressureWarning.value = false
                    }
                } catch (e: Exception) {
                    Timber.e(e, "Error in memory monitoring")
                }

                // Update every 2 seconds to reduce overhead
                delay(2000)
            }
        }
    }

    /**
     * Update context limit information
     */
    fun updateContextLimit(current: Int, max: Int) {
        contextLimit = current
        maxContextLimit = max
    }

    /**
     * Update GPU layer information
     */
    fun updateGpuLayers(offloaded: Int, total: Int) {
        offloadedLayers = offloaded
        totalLayers = total
    }

    /**
     * Reset all performance metrics
     */
    fun resetPerformanceMetrics() {
        tps = 0.0
        ttft = 0L
        latency = 0L
        memoryUsage = 0L
        contextLimit = 0
        maxContextLimit = 0
        tokensGenerated = 0
        totalGenerationTime = 0L
        offloadedLayers = -1
        totalLayers = -1
        Timber.d("Performance metrics reset")
    }

    /**
     * Calculate performance summary
     */
    fun getPerformanceSummary(): Map<String, Any> {
        return mapOf(
            "tokensPerSecond" to tps,
            "timeToFirstToken" to ttft,
            "averageLatency" to latency,
            "memoryUsage" to memoryUsage,
            "contextUsage" to "$contextLimit/$maxContextLimit",
            "gpuOffload" to "$offloadedLayers/$totalLayers",
            "totalTokens" to tokensGenerated,
            "totalTime" to totalGenerationTime
        )
    }
}
