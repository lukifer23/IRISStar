# IrisStar

**RECENTLY MODERNIZED - Major architectural improvements completed with clean MVVM structure and enhanced performance!**

## Project Description

IrisStar is a cutting-edge, llama.cpp-based offline Android chat application that delivers a private, secure, and fully offline AI chat experience with modern architecture and comprehensive features.

### Key Features

#### Core Features (Fully Implemented)
- **Offline-First Design**: All model inference performed locally on device; no data sent to external servers
- **Privacy-Focused**: User data and chat history remain on device; no collection or transmission
- **Expandable Models**: Download external GGUF models from Hugging Face with progress feedback
- **Advanced Configuration**: Comprehensive parameter controls (temperature, top-k/p, threads, context length)
- **GPU Acceleration**: Vulkan/OpenCL backends with automatic hardware detection and performance monitoring
- **Chat Management**: Persistent chat history with search, rename, delete functionality
- **Real-time Performance**: Live TPS, TTFT, memory usage, and context limit monitoring
- **Modern UI/UX**: Material 3 design with dark theme, haptic feedback, and accessibility features
- **Model Management**: Backend switching, model comparison, and benchmark testing

#### Architecture Highlights
- **Clean MVVM**: Decomposed monolithic ViewModel (2,633 â†’ ~1,200 lines) into specialized ViewModels
- **Dependency Injection**: Proper Hilt integration with single-responsibility components
- **Performance Optimized**: Real-time metrics, memory management, and GPU acceleration
- **Open Source**: Fully transparent development with comprehensive documentation

## Images

![Main Screen Screenshot](./images/main_screen.png)
**Main Screen**  
This is the main interface of the app where users can access all core functionalities.

![Chat Screen Screenshot](./images/chat_screen.png)
**Chat Screen**  
The chat feature allows users to interact in real-time and access AI-driven responses.

![Settings Screen Screenshot](./images/settings_screen.png)
**Settings Screen**  
Users can customize app preferences and configure their account settings here.

![Models Screen Screenshot](./images/models_screen.png)
**Models Screen**  
This screen displays available AI models and allows users to manage them efficiently.

![Parameters Screen Screenshot](./images/parameters_screen.png)
**Parameters Screen**  
Users can adjust parameters to fine-tune the app's performance based on their needs.

## Installation

**Note**: Pre-built releases are not currently available as this project is in active development. To run the application:

1. Clone this repository
2. Build the project using the instructions in the Build section below
3. Install the resulting APK on your Android device

## Features

### âœ… **Fully Implemented Features**

#### **Core Functionality**
- **Offline AI Chat**: Local LLM inference with no external dependencies
- **Privacy Protection**: Zero data collection or transmission
- **Model Downloads**: Seamless GGUF model acquisition from Hugging Face
- **Advanced Configuration**: Fine-tune all model parameters for optimal performance

#### **User Experience**
- **Modern UI**: Material 3 design with dark theme and haptic feedback
- **Chat Management**: Persistent conversations with full CRUD operations
- **Performance Monitoring**: Real-time TPS, latency, and memory metrics
- **Backend Flexibility**: Automatic GPU detection (Vulkan/OpenCL) with CPU fallback

#### **Technical Excellence**
- **Clean Architecture**: MVVM pattern with dependency injection
- **Performance Optimized**: GPU acceleration and memory management
- **Error Handling**: Comprehensive error states and user feedback
- **Accessibility**: Screen reader support and keyboard navigation

### ðŸ”„ **Advanced Features (Partially Implemented)**

- **Speech Integration**: Text-to-speech framework (TTS ready, STT framework in place)
- **Document Processing**: Basic text indexing implemented
- **Web Search**: API integration complete, UI integration pending
- **Multi-modal Support**: Vision processing foundation established

## Security & Privacy

- All model inference is performed locally on your device; no prompts or responses are sent to external servers.
- User data and chat history remain on the device and are not collected or transmitted.
- Network access is only required for downloading models. Once models are installed, the app can run fully offline.

## GPU Backends (Vulkan/OpenCL) on Android

IrisStar integrates llama.cpp GPU backends via dynamic loading for improved performance on compatible devices:

### Supported Backends

- **Vulkan**: Preferred on modern Android devices (especially Adreno GPUs). Loaded at runtime from system `libvulkan.so` and packaged `libggml-vulkan.so` plugin
- **OpenCL**: Loaded if vendor `libOpenCL.so` is available; the ggml OpenCL plugin is loaded dynamically when present
- **CPU**: Always available as fallback option

### Configuration and Testing

1. Navigate to Settings â†’ Detect Hardware to populate available backends (e.g., `CPU,Vulkan`)
2. Select your preferred Backend (Vulkan/OpenCL/CPU) in Settings
3. The app will unload and reload the model for the change to take effect
4. Use the Benchmark screen to run CPU vs GPU tests and compare throughput

### Performance Optimization

**Recommended Settings for Mobile GPUs:**

- Context length (`n_ctx`): 2048 tokens (default)
- Batch size (`n_batch`): 256 tokens (default)
- Micro-batch size (`n_ubatch`): 64 tokens (default)
- Generation limit: 256 tokens per response (default)
- GPU layers: Auto (offload as many as fit) or manually configure in Settings

**Troubleshooting:**

- If you see `failed to find ggml_backend_init in libggml-vulkan.so` during startup but Vulkan is reported as present, this is benign; the backend registry still succeeds
- GPU latency issues: Try smaller models or reduce context length in Settings
- Backend switching problems: The app forcefully unloads/reloads models on backend changes

### Runtime Diagnostics

- Native diagnostics snapshot available in UI logs after model load
- Includes backend registry, active contexts, GPU offload counts, KV cache size, and micro-batch configuration
- Backend switching is safe - runtime defers teardown when contexts are active
- GPU benchmark skips GPU path if device reports zero offload or CPU-forced session
- Token logging is gated to avoid excessive log traffic (verbose logs available in development builds)

## Model Selection and Performance

The performance of IrisStar is directly influenced by the size, speed, and compute requirements of the models you use. These factors significantly impact the overall user experience.

### Performance Considerations

- **Smaller models** are ideal for quicker interactions but may compromise slightly on response quality
- **Larger models** offer more comprehensive responses but require higher compute power and may result in slower speeds
- **GPU acceleration** can significantly improve performance on compatible devices

### Model Recommendations

On opening the app, users can download suggested models to optimize performance based on their preferences and device capabilities. Choose a model that best balances speed and quality for your specific use case.

**Important Disclaimer:**

- IrisStar may produce **inaccurate results** depending on the complexity of queries and model limitations
- Performance and accuracy are influenced by the size and type of model selected
- This application is in active development; expect potential bugs and incomplete features

## Prerequisites

- Install [JDK 17](https://adoptium.net/).
- Install [Android Studio](https://developer.android.com/studio).
- Initialize the `llama.cpp` submodule:

```bash
git submodule update --init --recursive
```

## Development Status

### Recent Major Achievements (COMPLETED âœ…)
- **Architectural Modernization**: Decomposed monolithic MainViewModel (2,633 lines) into clean, specialized ViewModels
- **Build System**: 100% compilation success (131+ errors â†’ 0 errors)
- **Performance**: Real-time monitoring, GPU acceleration, and memory optimization
- **UI/UX**: Complete Material 3 migration with dark theme and accessibility
- **Code Quality**: MVVM pattern, dependency injection, comprehensive error handling
- **Crash Resolution**: Fixed critical app launch crashes and dependency injection issues
- **Memory Management**: JNI memory leak fixes using upstream llama.cpp helpers

### Current Development Status (IN PROGRESS ðŸ”„)
- **Core Functionality**: App launches successfully, basic navigation works
- **Critical Issues**: Model loading, prompt sending, and settings screen need fixes
- **Performance**: UI responsiveness optimized with reduced recompositions
- **Architecture**: Clean MVVM structure established and functional

## Development Setup

### Prerequisites

- **JDK 17** - Install from [Eclipse Adoptium](https://adoptium.net/)
- **Android Studio** (latest stable) - [developer.android.com/studio](https://developer.android.com/studio)
- **Android SDK** - API level 28 or higher
- **Git** - For cloning and submodule management

### Building the Project

1. **Clone the repository**:
```bash
git clone https://github.com/lukifer23/IRISStar.git
cd IRISStar
```

2. **Initialize submodules** (includes llama.cpp):
```bash
git submodule update --init --recursive
```

3. **Open in Android Studio** and build the APK:
   - Import project from the cloned directory
   - Let Android Studio download dependencies
   - Build â†’ Make Project (Ctrl+F9)
   - Build â†’ Build Bundle/APK

4. **Run on Device**:
   - Connect Android device with USB debugging enabled
   - Run â†’ Run 'app' (Shift+F10)

### GPU Backend Support

**Vulkan Backend:**
- No extra steps required on device
- Ensure `vulkan-headers` are installed on host for cross-compilation (e.g., via Homebrew on macOS)

**OpenCL Backend:**
- Requires vendor `libOpenCL.so` on the target device
- The app loads the ggml OpenCL backend at runtime when available

### Device Setup for Development

1. Enable Developer Options on your Android device
2. Enable USB Debugging or Wireless Debugging
3. For wireless debugging:
   - Connect both devices to the same Wi-Fi network
   - Scan the QR code displayed in Android Studio
4. Select your device in Android Studio and run the app

**Note**: After installation, download at least one model through the app's interface to enable full functionality.

## Current Development Roadmap

### Immediate Priorities (Next 2-4 weeks)
1. **Performance Optimization**
   - Fix JNI memory leaks using upstream llama.cpp helpers
   - Optimize UI responsiveness and reduce recompositions
   - Implement proper coroutine cancellation and lifecycle management

2. **Feature Completion**
   - Complete voice input (STT) and text-to-speech (TTS) integration
   - Implement file attachment support with document processing
   - Enhance web search UI integration and result formatting

3. **Testing & Quality Assurance**
   - Add comprehensive unit tests for all ViewModels and repositories
   - Implement integration tests for critical user flows
   - Set up CI/CD pipeline with automated testing

4. **Security & Privacy Enhancements**
   - Implement SSL certificate pinning for network requests
   - Remove hardcoded secrets and add CI secrets scanning
   - Add biometric authentication for sensitive operations

### Remaining TODOs

#### **High Priority**
- [ ] Complete voice input/output functionality
- [ ] Fix hardcoded dimensions with centralized design tokens
- [ ] Implement comprehensive testing suite
- [ ] Memory leak fixes and performance optimization

#### **Medium Priority**
- [ ] Advanced document processing and RAG capabilities
- [ ] Multi-modal vision processing
- [ ] Enhanced model management and profiles
- [ ] Chat export/import functionality

#### **Low Priority**
- [ ] Additional UI polish and animations
- [ ] Advanced accessibility features
- [ ] Plugin system for function calling
- [ ] Offline web content processing

## Contributing

**The project has recently undergone major architectural improvements and is now in a stable, well-structured state for contributions!**

### Development Guidelines

1. **Check the [Modernization Plan](./docs/MODERNIZATION_PLAN.md)** for current priorities and architecture guidelines
2. **Fork the repository** and create a feature branch from `main`
3. **Follow established patterns**: MVVM architecture, dependency injection, comprehensive error handling
4. **Test thoroughly**: Unit tests, integration tests, and device testing required
5. **Update documentation** and the modernization plan for significant changes
6. **Submit detailed PRs** with clear descriptions and testing evidence

### Getting Started with Development

```bash
# Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/IRISStar.git
cd IRISStar

# Set up development environment
git submodule update --init --recursive

# Create a feature branch
git checkout -b feature/your-feature-name

# Make your changes following the established architecture
# ...

# Ensure tests pass and APK builds
./gradlew testDebugUnitTest
./gradlew assembleDebug

# Commit with clear messages
git commit -m 'feat: Add voice input functionality

- Implement STT framework integration
- Add permission handling for microphone
- Update UI with voice input button
- Add comprehensive error handling'

# Push and create PR
git push origin feature/your-feature-name
```

### Code Style & Architecture

- **Kotlin**: Follow official conventions with meaningful naming
- **MVVM**: Strict separation with Hilt dependency injection
- **Error Handling**: Comprehensive try/catch with user-friendly messages
- **Testing**: Unit tests for business logic, integration tests for flows
- **Documentation**: KDoc for public APIs, inline comments for complex logic

### Areas Needing Contributors

**Hot Priorities:**
- Voice input/output implementation
- Memory leak fixes and performance optimization
- Comprehensive test suite development
- Security hardening (SSL pinning, secrets management)

**Good First Issues:**
- UI component improvements and accessibility
- Documentation updates and examples
- Additional language support and localization
- Performance monitoring enhancements

**Note**: All contributions must maintain the project's core principles of privacy-first design and offline-first functionality.
